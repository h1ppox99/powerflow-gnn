import argparse
import numpy as np
import yaml
import json
import shutil
import sys
from copy import deepcopy
from pathlib import Path

# Import your existing modules
from src.models import load_model
from src.training.train import fit
from src.experiments.experiment_logger import log_experiment_run
from src.experiments.run_experiment import load_dataset

def set_nested_value(d, path, value):
    """Sets a value in a nested dictionary using a dot-notation string (e.g. 'train.lr')."""
    keys = path.split(".")
    for key in keys[:-1]:
        d = d.setdefault(key, {})
    d[keys[-1]] = value

def load_history_from_file(output_dir: Path):
    """Reads the metrics.jsonl file generated by train.py"""
    jsonl_path = output_dir / "metrics.jsonl"
    history = []
    if jsonl_path.exists():
        with open(jsonl_path, "r") as f:
            for line in f:
                if line.strip():
                    history.append(json.loads(line))
    return history

def main():
    parser = argparse.ArgumentParser(description="Run a hyperparameter sweep.")
    
    # Configuration
    parser.add_argument("--config", default="src/config/default.yaml", help="Path to base config file")
    
    # Sweep Parameters
    parser.add_argument("--param", required=True, help="Config parameter to sweep (e.g., 'train.physics_weight')")
    parser.add_argument("--start", type=float, required=True, help="Start value (power of 10 if --log is used)")
    parser.add_argument("--stop", type=float, required=True, help="Stop value (power of 10 if --log is used)")
    parser.add_argument("--steps", type=int, default=5, help="Number of steps in the sweep")
    parser.add_argument("--log", action="store_true", default=True, help="Use logarithmic spacing (base 10)")

    args = parser.parse_args()

    # 1. Load Base Config
    with open(args.config) as f:
        base_cfg = yaml.safe_load(f)

    # 2. Generate Sweep Values
    if args.log:
        # If start=-5 and stop=3, this generates 10^-5 to 10^3
        values = np.logspace(args.start, args.stop, num=args.steps)
        print(f"Sweeping '{args.param}' (Log Scale): {values}")
    else:
        values = np.linspace(args.start, args.stop, num=args.steps)
        print(f"Sweeping '{args.param}' (Linear Scale): {values}")

    # Output directory
    curves_dir = Path("experiment_curves") / args.param.replace(".", "_")
    curves_dir.mkdir(parents=True, exist_ok=True)

    print("Loading dataset (shared across sweep)...")
    dataset = load_dataset(base_cfg)

    for i, val in enumerate(values):
        val = float(val)
        print(f"\n--- [Sweep {i+1}/{len(values)}] {args.param} = {val:.4e} ---")

        # 3. Prepare Config
        cfg = deepcopy(base_cfg)
        
        # Inject the sweep value dynamically
        set_nested_value(cfg, args.param, val)

        # Configure unique logging folder
        temp_dir_name = f"sweep_{args.param}_{val:.2e}".replace(".", "_")
        temp_output_dir = Path("output") / temp_dir_name
        cfg.setdefault("logging", {})["output_dir"] = str(temp_output_dir)

        # 4. Train
        try:
            model = load_model(cfg, dataset)
            test_metrics = fit(model, dataset, cfg)
        except Exception as e:
            print(f"Run failed for {val:.2e}: {e}")
            continue

        # 5. Log & Save Data
        log_experiment_run(args.config, cfg, test_metrics)
        
        history = load_history_from_file(temp_output_dir)
        
        save_file = curves_dir / f"val_{val:.4e}.json"
        with open(save_file, "w") as f:
            json.dump({
                "parameter": args.param,
                "value": val,
                "test_metrics": test_metrics,
                "history": history
            }, f, indent=2)
            
        print(f"Saved results to {save_file}")
        
        # Cleanup temp logs (optional)
        # shutil.rmtree(temp_output_dir)

if __name__ == "__main__":
    main()