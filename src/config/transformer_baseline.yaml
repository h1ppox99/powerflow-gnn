# Transformer baseline matching PowerGraph paper

model:
  name: transformer
  hidden: 32
  num_layers: 3
  heads: 4
  dropout: 0.0

train:
  epochs: 50
  lr: 0.001
  weight_decay: 0.0
  batch_size: 32
  split:
    train: 0.85
    val: 0.05
    test: 0.10
  loss: mse
  scheduler:
    type: reduce_on_plateau
    factor: 0.1
    patience: 10

data:
  backend: powergraph
  grid: UK
  task: nodeopf
